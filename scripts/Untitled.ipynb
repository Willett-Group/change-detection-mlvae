{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc50494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os.path as path\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from math import comb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import dataloaders\n",
    "import networks\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84882d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', type=str)\n",
    "parser.add_argument('--model', type=str)\n",
    "\n",
    "parser.add_argument('--N', type=int, default=1000)\n",
    "parser.add_argument('--T', type=int, default=50)\n",
    "\n",
    "parser.add_argument('--nepochs', type=int)\n",
    "parser.add_argument('--batch_size', type=int, default=250)\n",
    "parser.add_argument('--initial_lr', type=float, default=0.001)\n",
    "parser.add_argument('--test', type=int, default=0)\n",
    "parser.add_argument('--test_method', default='1')\n",
    "# 1 for graph cut, using G(i, j) as the score\n",
    "# 2 for\n",
    "\n",
    "parser.add_argument('--log_file', default='log.txt')\n",
    "parser.add_argument('--continue_saved', default=False)\n",
    "\n",
    "parser.add_argument('--channels', default=3)\n",
    "parser.add_argument('--dim_x', default=64)\n",
    "parser.add_argument('--dim_y', default=64)\n",
    "\n",
    "# args = parser.parse_known_args()\n",
    "class Args:\n",
    "    dataset = 'cifar10'\n",
    "    model = 'contrastive'\n",
    "    N = 1000\n",
    "    T = 50\n",
    "    nepochs = 100\n",
    "    batch_size = 96\n",
    "    initial_lr = 0.001\n",
    "    test = 1\n",
    "    test_method = '1'\n",
    "    \n",
    "    log_file = 'log.txt'\n",
    "    continue_saved = False\n",
    "    channels = 3\n",
    "    dim_x = 64\n",
    "    dim_y = 64\n",
    "args = Args()\n",
    "    \n",
    "img_shape = (args.channels, args.dim_x, args.dim_y)\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05bcb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_cut(gs, eta):\n",
    "    E_r = 0\n",
    "    E_rc = 0\n",
    "    E_r_count = 0\n",
    "    E_rc_count = 0\n",
    "    for d1 in range(ds.T):\n",
    "        for d2 in range(ds.T):\n",
    "            if (d1 < eta and d2 < eta) or (d1 >= eta and d2 >= eta):\n",
    "                E_rc += gs[d1][d2]\n",
    "                E_rc_count += 1\n",
    "            else:\n",
    "                E_r += gs[d1][d2]\n",
    "                E_r_count += 1\n",
    "    score = E_r / E_r_count - E_rc / E_rc_count\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def compute_gs(model, ds, X):\n",
    "    ps = np.zeros((ds.T, ds.T))\n",
    "    gs = np.zeros((ds.T, ds.T))\n",
    "    for d1 in range(ds.T):\n",
    "        for d2 in range(ds.T):\n",
    "#             grid = make_grid(torch.cat((X[d1].unsqueeze_(0), X[d2].unsqueeze_(0))), nrow=1)\n",
    "#             plt.imshow(grid.cpu().permute(1, 2, 0))\n",
    "#             plt.show()\n",
    "#             plt.close()\n",
    "            # save_image(grid, path.join(root_dir, 'X_{}_{}.png'.format(d1, d2)))\n",
    "            p = model.forward(X[d1].unsqueeze_(0), X[d2].unsqueeze_(0))\n",
    "            p = torch.sigmoid(p).item()\n",
    "            #print(p)\n",
    "            if p == 1:\n",
    "                p -= 0.0001\n",
    "            ps[d1][d2] = p\n",
    "            g = p / (1-p)\n",
    "            gs[d1][d2] = g\n",
    "    return ps, gs\n",
    "\n",
    "\n",
    "def representation(model, ds, X, M):\n",
    "    random.seed(7)\n",
    "    L = torch.zeros((M,) + ds.data_dim)\n",
    "    for i in range(M):\n",
    "        index = random.choice(list(range(ds.n * ds.T)))\n",
    "        L[i] = torch.FloatTensor(ds.get_normal(index)[0])\n",
    "    L = L.to(device)\n",
    "    R = torch.zeros(X.size(0), M)\n",
    "    for i in range(X.size(0)):\n",
    "        R[i] = torch.FloatTensor([model.forward(X[i].unsqueeze_(0), L[m].unsqueeze_(0)) for m in range(M)])\n",
    "        R[i] = torch.sigmoid(R[i])\n",
    "\n",
    "    return R\n",
    "\n",
    "\n",
    "def option2a(R, eta):\n",
    "    r1, r2 = R[0:eta], R[eta:ds.T]\n",
    "    diff1 = r1 - torch.mean(r1, 0)\n",
    "    diff2 = r1 - torch.mean(r2, 0)\n",
    "\n",
    "    return torch.sum(diff1.pow(2)).detach().item() + \\\n",
    "            torch.sum(diff2.pow(2)).detach().item()\n",
    "\n",
    "\n",
    "def option2b(R, eta, alpha):\n",
    "    first_term = 0\n",
    "    second_term = 0\n",
    "    third_term = 0\n",
    "\n",
    "    T = R.size(0)\n",
    "    for t in range(T):\n",
    "        for tprime in range(T):\n",
    "            if t <= eta and tprime >= eta+1:\n",
    "                first_term += torch.sum(torch.pow(torch.abs(R[t]-R[tprime]), alpha))\n",
    "            elif t <= eta and tprime <= eta:\n",
    "                second_term += torch.sum(torch.pow(torch.abs(R[t] - R[tprime]), alpha))\n",
    "            else:\n",
    "                third_term += torch.sum(torch.pow(torch.abs(R[t] - R[tprime]), alpha))\n",
    "\n",
    "    first_term *= 2/(eta*(T-eta))\n",
    "    second_term /= comb(eta, 2)\n",
    "    third_term /= comb(T-eta, 2)\n",
    "\n",
    "    return eta*(t-eta)/T * (first_term - second_term - third_term)\n",
    "\n",
    "\n",
    "def validation_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (X, y) in enumerate(loader):\n",
    "            X1, X2 = X[0], X[1]\n",
    "            X1 = X1.to(device=device)\n",
    "            X2 = X2.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            p = model.forward(X1, X2)\n",
    "            p = p.view(p.size(0))\n",
    "            p = torch.sigmoid(p)\n",
    "\n",
    "            predictions = p >= 0.5\n",
    "            num_correct += (predictions == y).sum().item()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples\n",
    "\n",
    "\n",
    "def ts_sample_precision(ps, eta):\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    for d1 in range(ds.T):\n",
    "        for d2 in range(ds.T):\n",
    "            if (d1 < eta and d2 < eta) or (d1 >= eta and d2 >= eta):\n",
    "                if ps[d1][d2] < 0.5:\n",
    "                    positive_count += 1\n",
    "            else:\n",
    "                if ps[d1][d2] >= 0.5:\n",
    "                    negative_count += 1\n",
    "\n",
    "    negative_n = 2*eta*(ds.T-eta)\n",
    "    positive_n = ds.T*ds.T - negative_n\n",
    "    return positive_count / positive_n, negative_count / negative_n\n",
    "\n",
    "\n",
    "def train(model, ds, root_dir):\n",
    "    # should not shuffle here\n",
    "    train_loader = DataLoader(ds, args.batch_size, shuffle=False, drop_last=False)\n",
    "    test_loader = DataLoader(ds_test, args.batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    # load saved models if load_saved flag is true\n",
    "    if args.continue_saved:\n",
    "        model.load_state_dict(torch.load(path.join(root_dir, 'model')))\n",
    "\n",
    "    # optimizer definition\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=args.initial_lr\n",
    "    )\n",
    "\n",
    "    # load_saved is false when training is started from 0th iteration\n",
    "    if not args.continue_saved:\n",
    "        with open(path.join(root_dir, args.log_file), 'w') as log:\n",
    "            log.write('Epoch\\tIteration\\tLoss\\n')\n",
    "    # initialize summary writer\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    # start training\n",
    "    for epoch in range(0, args.nepochs):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "\n",
    "        # the total loss at each epoch after running all iterations of batches\n",
    "        iteration = 0\n",
    "        correct = 0\n",
    "\n",
    "        for batch_index, (X, y) in enumerate(train_loader):\n",
    "            # set zero grad for the optimizer\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # move data to cuda\n",
    "            X1, X2 = X[0], X[1]\n",
    "            X1 = X1.to(device=device)\n",
    "            X2 = X2.to(device=device)\n",
    "            \n",
    "            # grid = make_grid(torch.cat([X1, X2]), nrow=args.batch_size)\n",
    "            # save_image(grid, path.join(root_dir, 'X_{}.png'.format(iteration)))\n",
    "            iteration += 1\n",
    "\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            p = model.forward(X1, X2)\n",
    "            p = p.view(p.size(0))\n",
    "\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "            prediction = torch.sigmoid(p) > 0.5\n",
    "            correct += (prediction == y).sum().item() # training accuracy\n",
    "\n",
    "\n",
    "            loss = criterion(p, y.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            \n",
    "            # print losses\n",
    "            if batch_index % 50 == 0 or batch_index == args.batch_size - 1:\n",
    "                val_acc = validation_accuracy(test_loader, model)\n",
    "                print('\\n[%d/%d][%d/%d]\\tLoss: %.2E\\tVal Acc: %.2E' %\n",
    "                      (epoch, args.nepochs, batch_index, len(train_loader),\n",
    "                       loss.item(), val_acc))\n",
    "                # get precision on ts sample\n",
    "                ith = 0\n",
    "                X_test = ds_test.get_ts_sample(ith).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    ps, gs = compute_gs(model, ds, X_test)\n",
    "                    positive_precision, negative_precision = ts_sample_precision(ps, ds.cps[ith])\n",
    "                    print(\"positive, negative samples precision %.3f, %.3f\" % (positive_precision, negative_precision))\n",
    "                    print(ps)\n",
    "                    model.train()\n",
    "\n",
    "            # write to log\n",
    "            with open(path.join(root_dir, args.log_file), 'a') as log:\n",
    "                log.write('{0}\\t{1}\\t{2}\\n'.format(\n",
    "                    epoch,\n",
    "                    batch_index,\n",
    "                    loss.detach().item()\n",
    "                ))\n",
    "\n",
    "            # write to tensorboard\n",
    "            itr = epoch * (int(len(ds) / args.batch_size) + 1) + batch_index\n",
    "            writer.add_scalar('Loss', loss.detach().item(), itr)\n",
    "\n",
    "        print('Training accuracy %.4E' % (correct / len(ds)))\n",
    "        # save the model at every epoch\n",
    "        torch.save(model.state_dict(), path.join(root_dir, 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "576bf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, ds, dir):\n",
    "    print(\"Running tests...\")\n",
    "    if args.test_method == '1':\n",
    "        test_dir = 'errors_graph_cut'\n",
    "    else:\n",
    "        test_dir = 'errors_'+args.test_method\n",
    "    test_dir_path = path.join(dir, test_dir)\n",
    "    if not path.exists(test_dir_path):\n",
    "        os.makedirs(test_dir_path)\n",
    "\n",
    "    eta_hats = []  # save predicted change points\n",
    "    etas = []\n",
    "    # iterate over ts test samples X_1, X_2, etc...\n",
    "    all_i = range(ds.n) if not args.dataset == 'clevr' else [args.T*6*(i-1)+j for i in range(1, 7) for j in range(5)]\n",
    "    for i in all_i:\n",
    "        print(\"Running\", i)\n",
    "        etas.append(ds.cps[i])\n",
    "        # load test sample X_i\n",
    "        X = ds.get_ts_sample(i).to(device)\n",
    "\n",
    "        scores = {}  # save errors for all candidate etas\n",
    "        min_eta = 2\n",
    "        max_eta = ds.T - 2\n",
    "        max_score = -float('inf')\n",
    "        eta_hat = -1\n",
    "\n",
    "        if args.test_method == '1':\n",
    "            ps, gs = compute_gs(model, ds, X)\n",
    "            ps_df = pd.DataFrame(ps)\n",
    "            ps_tf_df = pd.DataFrame(ps > 0.5, dtype=int)\n",
    "            ps_tf_df.to_csv(path.join(test_dir_path, 'X_{}_binary.csv'.format(i)), index=True)\n",
    "            ps_df.to_csv(path.join(test_dir_path, 'X_{}.csv'.format(i)), index=True)\n",
    "            grid = make_grid(X, nrow=args.T)\n",
    "            save_image(grid, path.join(test_dir_path, 'X_{}.png'.format(i)))\n",
    "            \n",
    "            \n",
    "        for eta in range(min_eta, max_eta + 1):\n",
    "            # R = representation(model, ds, X, 20)\n",
    "            if args.test_method == '1':\n",
    "                score = graph_cut(gs, eta)\n",
    "            elif args.test_method == '2a':\n",
    "                score = option2a(R, eta)\n",
    "            elif args.test_method == '2b':\n",
    "                score = option2b(R, eta, 1)\n",
    "                print(score)\n",
    "            elif args.test_method == '2c':\n",
    "                pass\n",
    "\n",
    "            scores[eta] = score\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                eta_hat = eta\n",
    "        eta_hats.append(eta_hat)\n",
    "\n",
    "        # save errors\n",
    "        plt.scatter(list(scores.keys()), list(scores.values()))\n",
    "        plt.axvline(x=ds.cps[i])\n",
    "        plt.axvline(x=eta_hat, color='r')\n",
    "        plt.xlabel('etas (red: eta_hat, blue: true eta)')\n",
    "        plt.ylabel('errors')\n",
    "        plt.savefig(path.join(test_dir_path, 'X_{}_errors.png'.format(i)))\n",
    "        plt.close()\n",
    "\n",
    "    # compute mean of |eta-eta_hat| among all test samples\n",
    "    diff = np.abs(np.asarray(etas) - np.asarray(eta_hats))\n",
    "    score_mean = np.mean(diff)\n",
    "    score_std = np.std(diff)\n",
    "    # keep track of the errors associated with epochs\n",
    "    with open(path.join(test_dir_path, 'test_stats.txt'), 'w') as f:\n",
    "        json.dump({'mean': score_mean, 'std': score_std}, f, indent=2)\n",
    "    # save etas and eta_hats\n",
    "    with open(test_dir_path + '/cps.txt', 'w') as cps_r:\n",
    "        for tmp in eta_hats:\n",
    "            cps_r.write('{} '.format(tmp))\n",
    "        cps_r.write('\\n')\n",
    "        for tmp in etas:\n",
    "            cps_r.write('{} '.format(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ecf6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training and testing datasets...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Creating models...\n",
      "Running tests...\n",
      "Running 0\n",
      "Running 1\n",
      "Running 2\n",
      "Running 3\n",
      "Running 4\n",
      "Running 5\n",
      "Running 6\n",
      "Running 7\n",
      "Running 8\n",
      "Running 9\n",
      "Running 10\n",
      "Running 11\n",
      "Running 12\n",
      "Running 13\n",
      "Running 14\n",
      "Running 15\n",
      "Running 16\n",
      "Running 17\n",
      "Running 18\n",
      "Running 19\n",
      "Running 20\n",
      "Running 21\n",
      "Running 22\n",
      "Running 23\n",
      "Running 24\n",
      "Running 25\n",
      "Running 26\n",
      "Running 27\n",
      "Running 28\n",
      "Running 29\n",
      "Running 30\n",
      "Running 31\n",
      "Running 32\n",
      "Running 33\n",
      "Running 34\n",
      "Running 35\n",
      "Running 36\n",
      "Running 37\n",
      "Running 38\n",
      "Running 39\n",
      "Running 40\n",
      "Running 41\n",
      "Running 42\n",
      "Running 43\n",
      "Running 44\n",
      "Running 45\n",
      "Running 46\n",
      "Running 47\n",
      "Running 48\n",
      "Running 49\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # create parent directories, like 'experiments/cifar10/linearmlvae_50'\n",
    "    # and 'experiments/cifar10/dfcmlvae_128'\n",
    "    dir0 = 'experiments'\n",
    "    dir1 = path.join(dir0, args.dataset)\n",
    "    dir2 = path.join(dir1, args.model)\n",
    "    for d in [dir0, dir1, dir2]:\n",
    "        if not path.exists(d):\n",
    "            os.makedirs(d)\n",
    "\n",
    "    # use cpu or gpu\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print('Creating training and testing datasets...')\n",
    "    trans = transforms.Compose([transforms.Resize([args.dim_x, args.dim_y]),\n",
    "                                transforms.ToTensor()\n",
    "                                ])\n",
    "    if args.dataset == 'mnist':\n",
    "        ds = dataloaders.mnist_contrastive_explicit(1000, args.T, 50, train=True, transform=trans)\n",
    "        ds_test = dataloaders.mnist_contrastive_explicit(50, args.T, 50, train=False, seed=7, transform=trans)\n",
    "    elif args.dataset == 'cifar10':\n",
    "        ds = dataloaders.cifar10_contrastive(1000, args.T, train=True, transform=trans)\n",
    "        ds_test = dataloaders.cifar10_contrastive_explicit(50, args.T, 50, train=False, seed=7, transform=trans)\n",
    "    elif args.dataset == 'celeba':\n",
    "        ds = dataloaders.celeba_contrastive_explicit(1000, args.T, 50, train=True, transform=trans)\n",
    "        ds_test = dataloaders.celeba_contrastive_explicit(50, args.T, 50, train=False, seed=7, transform=trans)\n",
    "    elif args.dataset == 'clevr':\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"invalid dataset name\")\n",
    "\n",
    "    print('Creating models...')\n",
    "    if args.model == 'contrastive':\n",
    "        encoder = networks.resnet18()\n",
    "        model = networks.TwoPathNetwork(3*64*64, predefined_encoder=encoder).to(device)\n",
    "        # model = networks.TwoPathNetwork(3 * 64 * 64, embedding_size=100).to(device)\n",
    "    else:\n",
    "        raise Exception(\"invalid model name\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    existing_dirs = [int(f) for f in os.listdir(dir2) if f.isdigit()]\n",
    "    dir_test = max(existing_dirs)\n",
    "    if args.test == 0:\n",
    "        # create new directory for this training run\n",
    "        new = '1' if not existing_dirs else str(max(existing_dirs) + 1)\n",
    "        # root dir is the directory of this particular run of experiment\n",
    "        # all data produced by training and testing will be saved in this root dir\n",
    "        root_dir = path.join(dir2, new)\n",
    "        if not path.exists(root_dir):\n",
    "            os.makedirs(root_dir)\n",
    "        # save args\n",
    "        with open(path.join(root_dir, 'args.txt'), 'w') as f:\n",
    "            json.dump(args.__dict__, f, indent=2)\n",
    "        train(model, ds, root_dir)\n",
    "    else:\n",
    "        root_dir = path.join(dir2, str(dir_test))\n",
    "        model.load_state_dict(torch.load(path.join(root_dir, 'model')))\n",
    "        model.eval()\n",
    "        test(model, ds_test, root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d16287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e16fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
